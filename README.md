# ButaChanRLüê∑
Welcome to ButaChanRL! ButaChanRL is a Deep Reinforcement Learning (DRL) framework created for easy testing and implementation of Reinforcement Learning (RL) agents.

Built on the PyTorch backend, ButaChanRL provides a collection of state-of-the-art deep reinforcement learning algorithms, including DQN, Double DQN, Dueling DQN, and Prioritized Experience Replay (PER is on the way!).

For Continuous action space problems, Continuous and Discrete Actor-Critic algorithms (Vanilla actor-critic, A2C, SAC) are at the development state.

Documentation:

A documentation will be created later for detailed information on ButaChanRL's modules, classes, and methods, refer to the documentation.

Examples:

Explore the examples directory for sample scripts demonstrating the use of ButaChanRL with different environments and algorithms.
ButaChanRL can easily be used with Gymnasium environments like other RL packages.

For the example, you can look at run.py. Just change the "CartPole-v1" to other Discrete Gym environment and you are good to go!

![alt text](https://github.com/thawtar/ButaChanRL/blob/master/images/training.png)


Requirements:

Requirements for ButaChanRL can be installed via pip as follows:

```
pip install numpy torch matplotlib tqdm gymnasium
```

Contributing:
Contributions to ButaChanRL are welcome! Please refer to CONTRIBUTING.md for guidelines on how to contribute.

License:
This project is licensed under the MIT License - see the LICENSE file for details.

Happy Reinforcement Learning with ButaChanRL! üê∑
